{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text\n",
    "\n",
    "Generating text can be done by mimicing the probabilities of words following other words. Let's try it with \"The Garden Party.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenParty = open('../Texts/garden-party.md').read().split('\\n# ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2. THE GARDEN PARTY.\\n\\nAnd afte'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gardenParty[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from random import choice\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build a dictionary, where each type (i.e. word) will be a key, and the value will be a list of words that follow that word. For example, in the sentence, \"the quick brown fox jumped over the lazy dogs,\" that dictionary would look like: \n",
    "\n",
    "```python\n",
    "{\"the\": [\"quick\", \"lazy\"],\n",
    " \"quick\": [\"brown\"],\n",
    " \"fox\": [\"jumped\"],\n",
    " \"over\": [\"the\"],\n",
    " \"lazy\": [\"dogs\"],\n",
    " \"dogs\": [\".\"]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenDoc = nlp(gardenParty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenDist = {}\n",
    "for word in gardenDoc[:-1]:\n",
    "    nextWord = gardenDoc[word.i + 1].text\n",
    "    wordText = word.text\n",
    "    if wordText not in gardenDist: \n",
    "        gardenDist[wordText] = [nextWord]\n",
    "    else: \n",
    "        gardenDist[wordText].append(nextWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all', 'the', 'breakfast', 'the', 'all', 'that', '\\n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gardenDist['after']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to start the Markov chain, choose a random word from the dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knot'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = choice(list(gardenDist.keys()))\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then choose the next word from among those that follow it. Repeat this, using that following word as your new seed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = [seed]\n",
    "for i in range(50):     \n",
    "    if seed in gardenDist: \n",
    "        nextWord = choice(gardenDist[seed])\n",
    "        seed = nextWord\n",
    "        chain.append(nextWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knot', 'of', 'these', 'tables', 'into', 'the', 'man', 'was', 'going', 'to', 'life', ',', 'and', 'feathery', ',', '\"', 'the', 'same', ',', 'watching', '.', '\"', 'Know', 'them', 'out', 'so', 'soon', 'after', 'all', '.', '\"', 'Darling', '!', 'And', 'what', \"'s\", 'make', 'up', 'and', 'the', 'woman', 'in', 'a', 'muffled', 'thud', '.', 'At', 'the', 'passage', 'seemed', 'quite']\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean it up with some quick-and-dirty detokenizing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knot of these tables into the man was going to life, and feathery, \" the same, watching. \" Know them out so soon after all. \" Darling ! And what 's make up and the woman in a muffled thud. At the passage seemed quite\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(chain).replace('\\n', '').replace(' .', '.').replace(' ,', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
