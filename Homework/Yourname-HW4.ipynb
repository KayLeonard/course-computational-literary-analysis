{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "## Your name here\n",
    "\n",
    "Instructions: \n",
    "\n",
    "1. Replace \"yourname\" in the title of this notebook, and \"your name here\" in this header, with your name. \n",
    "2. Complete all questions/problems. **Make sure to run all cells so that your output is visible**. You can usually do this by choosing \"restart & run all\" from the Kernel menu. \n",
    "3. Email me your notebook (.ipynb file) to jonathan.reeve@columbia.edu, with the subject \"yourname - HW4,\" replacing \"yourname\" with your name. Please don't email me archives (`.zip` or `.tar.gz`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install SpaCy and the SpaCy language model called `en_core_web_lg`. It is important that you get this particular language model, as the others don't have the features we'll need. \n",
    "\n",
    "You can work together in groups (probably in groups where you all run the same operating system). \n",
    "\n",
    "There are installation instructions [here on the SpaCy website](https://spacy.io/usage/) that list a number of command-line commands to run. To run command-line commands: \n",
    "\n",
    " - **Linux**: open a terminal. \n",
    " - **MacOS**: open the Terminal app. (Hint: you can open Spotlight, the magnifying glass icon in the upper right, and type \"terminal\")\n",
    " - **Windows**: open Powershell. (Open the Start menu, then type \"powershell.\") Alternatively, download Git BASH, which is included in GitHub Desktop. \n",
    "\n",
    "Whenever you see command-line commands, they're usually prefixed with `$` or `#`. A `$` means to run the command as a regular user, and a `#` means to prefix your command with `sudo`. You'll generally only see `$`, and you're already running as a regular user, so all you'll need to do is to type in the command that follows the `$`, i.e. not including the `$`. So if the command is shown in the SpaCy docs as `$ conda install -c conda-forge spacy`, open a terminal and type `conda install -c conda-forge spacy`, exactly as written. \n",
    "\n",
    "When following the SpaCy instructions, you'll want to choose `conda` as your package manager (because you've installed Anaconda), and 'python3' as your Python version, since we're using Python 3 in this course. Don't select `virtualenv` unless you really know what you're doing. \n",
    "\n",
    "To show that you've successfully installed this stack, please run the two cells below, to show that it's not giving you errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-76a01d9c502b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ceb8f64bba80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the corpus that you'll use for your final project, load it into this notebook, put it into a single variable (e.g., a dictionary), and show some basic text statistics. \n",
    " \n",
    "Feel free to use [corpus-db.org](http://corpus-db.org) to assemble your corpus. If you need any help in using it, please ask in the chatroom! You can use it to get, say, 30 detective novels relatively easily, or 30 novels that feature young women, or 30 novels set in Paris. You can also get all the works by a certain author this way. But be careful to know exactly what texts you're getting. Project Gutenberg includes texts in a number of languages, prune your texts carefully. \n",
    "\n",
    "Stick with English texts, please. NLP in other languages is possible, but requires a different set of tokenizers and other tools that we haven't used yet in this course. It's also good idea to work with texts that are originally written in English, since translations have the problem of introducing translator's word choices to the set of word choices that the author has already made.\n",
    "\n",
    "Your corpus should be a collection of texts, stored in one variable. However, it doesn't have to be a collection of *works*. Rather, it can be all the narratives in _The Moonstone_, all of Katherine Mansfield's stories, all of Joyce's stories, or some combination of the above, based on theme or genre. It can also be all the novels of a certain writer, or of five writers. \n",
    "\n",
    "Comparisons make for good corpora. Why not compare, say, all of our Joyce stories to all of our Mansfield stories? \n",
    "\n",
    "You can also use certain APIs to get texts like book reviews from sites like Goodreads. Use `requests.get` along with a URL you get from the API's documentation. Maybe you're interested in comparing texts with book reviews? \n",
    "\n",
    "Your corpus might change a little by the time you finish your final project, and that's OK, but try not to change it completely, if you can. \n",
    "\n",
    "Make sure to clean your corpus of paratext: tables of contents, Project Gutenberg copyright licenses, etc, since these will throw off text statistics. \n",
    "\n",
    "Show at least four types of text statistics, like: \n",
    " - Length of each text or text segment, in words. \n",
    " - Titles (labels) for each text or text segment. \n",
    " - Type/token ratio of each text or text segment. What do you notice here? \n",
    " - Collocations and/or frequent content n-grams for each. What do you notice? \n",
    " - A pattern like JJ-JJ-JJ-NN, or 'like a JJ NN'. \n",
    " - Anything else you're interested in knowing/showing about this corpus. \n",
    "\n",
    " \n",
    "**Include at least one paragraph of markdown where you describe your exploratory analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Complete ONE of the following mini-projects. \n",
    "\n",
    "**For each, please write at least one paragraph where you describe and explain your results in terms of the text(s) you're studying.**\n",
    "\n",
    "1. Topic-model your corpus using LDA. What do you notice? Create a visualization of it, if you want. \n",
    "2. Explore the differences between quoted and non-quoted text in either _The Moonstone_ or in Mansfield's stories. What kinds of words/POSes appear more often in each category? Use any techniques we've learned so far. \n",
    "3. Explore the Brown Corpus, by category. What kinds of words/POSes appear more often in each category? Create a visualization or two of your explorations. \n",
    "4. Conduct a comparative stylometric analysis of a corpus of your choosing, using PCA. (Maybe the Brown Corpus, Inaugural Address Corpus, or a corpus of chapters in _The Moonstone_. According to your PCA output, which are the outliers (the most statistically dissimilar from the others)? Which are the most similar to each other? Why do you think this is? \n",
    "5. Make a simple genre categorizer that tries to guess the genre of a text, based on word frequencies derived from the Brown corpus. Test it on a few texts, like Mansfield's stories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your markdown here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
